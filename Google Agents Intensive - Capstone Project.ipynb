{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration Complete.\n",
      "--- ðŸ§  Lead Analyst Team Started ---\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > \n",
      "I have a CSV file named 'Euro_Daily_Trends.csv' in the current folder.\n",
      "It contains daily metrics for different European entities.\n",
      "\n",
      "I want to understand the drivers behind the main trends in this dataset.\n",
      "Please follow your exploration â†’ hypotheses â†’ testing â†’ synthesis workflow,\n",
      "and focus on finding non-obvious relationships rather than just describing the data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeadAnalyst > Excellent. I will now begin a systematic analysis of the `Euro_Daily_Trends.csv` dataset to identify the key drivers of its main trends.\n",
      "\n",
      "### Phase 1: Exploration\n",
      "\n",
      "First, I need to understand the structure and content of the dataset. I will ask my Data Engineer to load the file and provide a basic overview, including the first few rows, the data types of the columns, and summary statistics. This will help me identify the key metrics and dimensions for our analysis.\n",
      "\n",
      "ðŸ“¢ [MANAGER -> ENGINEER]: Load the 'Euro_Daily_Trends.csv' file into a pandas DataFrame. Then, please provide the following:\n",
      "1.  The first 5 rows of the DataFrame.\n",
      "2.  The data types of each column (info).\n",
      "3.  A descriptive statistical summary of the numerical columns.\n",
      "ðŸ§µ [ENGINEER SESSION] Created/using session 'internal_engineer_session'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– [ENGINEER EVENT] role=model\n",
      "   ðŸ—£ï¸ ENGINEER TEXT:\n",
      "   Okay, I will load the `Euro_Daily_Trends.csv` file into a pandas DataFrame. Then, I will display the first 5 rows, the data type information for each column, and a statistical summary of the numerical columns.\n",
      "   ðŸ› ï¸ ENGINEER TOOL CALL:\n",
      "      name: run_python_kernel\n",
      "      args: {'script': '\\nimport pandas as pd\\n\\n# Load the dataset\\ntry:\\n    df = pd.read_csv(\\'Euro_Daily_Trends.csv\\')\\n    print(\"DataFrame loaded successfully.\\n\")\\n    # 1. Display the first 5 rows\\n    print(\"First 5 rows of the DataFrame:\")\\n    print(df.head())\\n    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\\n\\n    # 2. Display the data types of each column\\n    print(\"DataFrame Info:\")\\n    df.info()\\n    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\\n\\n    # 3. Display descriptive statistics\\n    print(\"Descriptive Statistics for numerical columns:\")\\n    print(df.describe())\\n\\nexcept FileNotFoundError:\\n    print(\"Error: \\'Euro_Daily_Trends.csv\\' not found. Please ensure the file is in the correct directory.\")\\ncatch:\\n    print(f\"An unexpected error occurred: {e}\")\\n'}\n",
      "\n",
      "ðŸ§ª [ENGINEER -> KERNEL] Executing script:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "try:\n",
      "    df = pd.read_csv('Euro_Daily_Trends.csv')\n",
      "    print(\"DataFrame loaded successfully.\n",
      "\")\n",
      "    # 1. Display the first 5 rows\n",
      "    print(\"First 5 rows of the DataFrame:\")\n",
      "    print(df.head())\n",
      "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "\n",
      "    # 2. Display the data types of each column\n",
      "    print(\"DataFrame Info:\")\n",
      "    df.info()\n",
      "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "\n",
      "    # 3. Display descriptive statistics\n",
      "    print(\"Descriptive Statistics for numerical columns:\")\n",
      "    print(df.describe())\n",
      "\n",
      "except FileNotFoundError:\n",
      "    print(\"Error: 'Euro_Daily_Trends.csv' not found. Please ensure the file is in the correct directory.\")\n",
      "catch:\n",
      "    print(f\"An unexpected error occurred: {e}\")\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“¤ [KERNEL OUTPUT]\n",
      "--------------------------------------------------------------------------------\n",
      "Runtime Error: Traceback (most recent call last):\n",
      "  File \"/var/folders/nz/qh5z9ww95hv6117b9_styjgc0000gn/T/ipykernel_53395/3717009531.py\", line 63, in execute\n",
      "    exec(script, self.namespace, self.namespace)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 7\n",
      "    print(\"DataFrame loaded successfully.\n",
      "          ^\n",
      "SyntaxError: unterminated string literal (detected at line 7)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¤– [ENGINEER EVENT] role=user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– [ENGINEER EVENT] role=model\n",
      "   ðŸ—£ï¸ ENGINEER TEXT:\n",
      "   It appears my previous code failed due to a `SyntaxError`. The error was caused by an unclosed string in a `print` statement. I have fixed this syntax issue and will now rerun the script to load the `Euro_Daily_Trends.csv` data and provide the requested summaries.\n",
      "   ðŸ› ï¸ ENGINEER TOOL CALL:\n",
      "      name: run_python_kernel\n",
      "      args: {'script': '\\nimport pandas as pd\\n\\n# Load the dataset\\ntry:\\n    df = pd.read_csv(\\'Euro_Daily_Trends.csv\\')\\n    print(\"DataFrame loaded successfully.\")\\n    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\\n\\n    # 1. Display the first 5 rows\\n    print(\"First 5 rows of the DataFrame:\")\\n    print(df.head())\\n    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\\n\\n    # 2. Display the data types of each column\\n    print(\"DataFrame Info:\")\\n    df.info()\\n    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\\n\\n    # 3. Display descriptive statistics\\n    print(\"Descriptive Statistics for numerical columns:\")\\n    print(df.describe())\\n\\nexcept FileNotFoundError:\\n    print(\"Error: \\'Euro_Daily_Trends.csv\\' not found. Please ensure the file is in the correct directory.\")\\nexcept Exception as e:\\n    print(f\"An unexpected error occurred: {e}\")\\n'}\n",
      "\n",
      "ðŸ§ª [ENGINEER -> KERNEL] Executing script:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "try:\n",
      "    df = pd.read_csv('Euro_Daily_Trends.csv')\n",
      "    print(\"DataFrame loaded successfully.\")\n",
      "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "\n",
      "    # 1. Display the first 5 rows\n",
      "    print(\"First 5 rows of the DataFrame:\")\n",
      "    print(df.head())\n",
      "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "\n",
      "    # 2. Display the data types of each column\n",
      "    print(\"DataFrame Info:\")\n",
      "    df.info()\n",
      "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "\n",
      "    # 3. Display descriptive statistics\n",
      "    print(\"Descriptive Statistics for numerical columns:\")\n",
      "    print(df.describe())\n",
      "\n",
      "except FileNotFoundError:\n",
      "    print(\"Error: 'Euro_Daily_Trends.csv' not found. Please ensure the file is in the correct directory.\")\n",
      "except Exception as e:\n",
      "    print(f\"An unexpected error occurred: {e}\")\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“¤ [KERNEL OUTPUT]\n",
      "--------------------------------------------------------------------------------\n",
      "DataFrame loaded successfully.\n",
      "\n",
      "==================================================\n",
      "\n",
      "First 5 rows of the DataFrame:\n",
      "         Date       City      Country Day_of_Week Weather_Condition  \\\n",
      "0  2024-03-01  Amsterdam  Netherlands      Friday             Rainy   \n",
      "1  2024-03-01     Madrid        Spain      Friday             Sunny   \n",
      "2  2024-03-01     Berlin      Germany      Friday            Cloudy   \n",
      "3  2024-03-02  Amsterdam  Netherlands    Saturday             Rainy   \n",
      "4  2024-03-03  Amsterdam  Netherlands      Sunday            Cloudy   \n",
      "\n",
      "   Avg_Temp_C  Avg_Commute_Time_Mins Primary_Transport_Mode  \\\n",
      "0           8                     45                  Metro   \n",
      "1          18                     30                  Metro   \n",
      "2           6                     35                Bicycle   \n",
      "3           9                     15                   Walk   \n",
      "4          10                     10                   Walk   \n",
      "\n",
      "   Avg_Coffee_Cups_Per_Person  Work_Productivity_Index  \\\n",
      "0                         3.2                      7.8   \n",
      "1                         2.1                      8.2   \n",
      "2                         3.5                      7.5   \n",
      "3                         4.1                      4.2   \n",
      "4                         4.5                      3.5   \n",
      "\n",
      "   Public_Transit_Strike_Flag  \n",
      "0                       False  \n",
      "1                       False  \n",
      "2                       False  \n",
      "3                       False  \n",
      "4                       False  \n",
      "\n",
      "==================================================\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        30 non-null     object \n",
      " 1   City                        30 non-null     object \n",
      " 2   Country                     30 non-null     object \n",
      " 3   Day_of_Week                 30 non-null     object \n",
      " 4   Weather_Condition           30 non-null     object \n",
      " 5   Avg_Temp_C                  30 non-null     int64  \n",
      " 6   Avg_Commute_Time_Mins       30 non-null     int64  \n",
      " 7   Primary_Transport_Mode      30 non-null     object \n",
      " 8   Avg_Coffee_Cups_Per_Person  30 non-null     float64\n",
      " 9   Work_Productivity_Index     30 non-null     float64\n",
      " 10  Public_Transit_Strike_Flag  30 non-null     bool   \n",
      "dtypes: bool(1), float64(2), int64(2), object(6)\n",
      "memory usage: 2.5+ KB\n",
      "\n",
      "==================================================\n",
      "\n",
      "Descriptive Statistics for numerical columns:\n",
      "       Avg_Temp_C  Avg_Commute_Time_Mins  Avg_Coffee_Cups_Per_Person  \\\n",
      "count   30.000000              30.000000                   30.000000   \n",
      "mean    11.500000              41.133333                    3.143333   \n",
      "std      5.184526              17.018719                    0.800294   \n",
      "min      2.000000              10.000000                    1.800000   \n",
      "25%      8.000000              28.000000                    2.500000   \n",
      "50%     10.000000              42.000000                    3.150000   \n",
      "75%     14.000000              50.000000                    3.800000   \n",
      "max     23.000000              90.000000                    4.500000   \n",
      "\n",
      "       Work_Productivity_Index  \n",
      "count                30.000000  \n",
      "mean                  7.423333  \n",
      "std                   1.303492  \n",
      "min                   3.500000  \n",
      "25%                   7.000000  \n",
      "50%                   7.550000  \n",
      "75%                   8.375000  \n",
      "max                   9.100000  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¤– [ENGINEER EVENT] role=user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– [ENGINEER EVENT] role=model\n",
      "   ðŸ—£ï¸ ENGINEER TEXT:\n",
      "   The `Euro_Daily_Trends.csv` file has been successfully loaded. Here is a summary of the data:\n",
      "   \n",
      "   *   **First 5 Rows**: The dataset includes daily records for cities like Amsterdam, Madrid, and Berlin. The columns track the date, city, country, day of the week, weather, average temperature, commute time, primary transport mode, coffee consumption, work productivity, and whether there was a public transit strike.\n",
      "   \n",
      "   *   **Data Types**: The DataFrame contains 30 rows and 11 columns with no missing values. The data types are a mix of `object` (for text data like City and Country), `int64` (for Temperature and Commute Time), `float64` (for Coffee Cups and Productivity), and `bool` (for the Strike Flag).\n",
      "   \n",
      "   *   **Statistical Summary**:\n",
      "       *   **Temperature (`Avg_Temp_C`)**: The average temperature is 11.5Â°C, with a range from 2Â°C to 23Â°C.\n",
      "       *   **Commute Time (`Avg_Commute_Time_Mins`)**: The average commute time is about 41 minutes, varying significantly from a minimum of 10 to a maximum of 90 minutes.\n",
      "       *   **Coffee Consumption (`Avg_Coffee_Cups_Per_Person`)**: On average, a person drinks about 3.1 cups of coffee.\n",
      "       *   **Work Productivity (`Work_Productivity_Index`)**: The work productivity index has a mean of 7.42, with a scale from 3.5 to 9.1.\n",
      "\n",
      "ðŸ“‰ [ENGINEER -> MANAGER]: Final aggregated response delivered.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2, model: gemini-2.5-pro\\nPlease retry in 32.726169318s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}, 'quotaValue': '2'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 345\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- ðŸ§  Lead Analyst Team Started ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    341\u001b[39m runner = InMemoryRunner(agent=lead_analyst, app_name=\u001b[33m\"\u001b[39m\u001b[33mlead_analyst_app\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(user_query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/runners.py:1023\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1021\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1024\u001b[39m     user_id=user_id,\n\u001b[32m   1025\u001b[39m     session_id=session.id,\n\u001b[32m   1026\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1027\u001b[39m     run_config=run_config,\n\u001b[32m   1028\u001b[39m ):\n\u001b[32m   1029\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1030\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/agents/llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:433\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    422\u001b[39m model_response_event = Event(\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    424\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    425\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    426\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    427\u001b[39m )\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    430\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    436\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    437\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m         )\n\u001b[32m    442\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    443\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:804\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    801\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:788\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    775\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    776\u001b[39m     llm_request,\n\u001b[32m    777\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    778\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    779\u001b[39m )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    781\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    782\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     )\n\u001b[32m    787\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    789\u001b[39m     trace_call_llm(\n\u001b[32m    790\u001b[39m         invocation_context,\n\u001b[32m    791\u001b[39m         model_response_event.id,\n\u001b[32m    792\u001b[39m         llm_request,\n\u001b[32m    793\u001b[39m         llm_response,\n\u001b[32m    794\u001b[39m     )\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:998\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    996\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:982\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    983\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/adk/models/google_llm.py:181\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m close_result\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    182\u001b[39m       model=llm_request.model,\n\u001b[32m    183\u001b[39m       contents=llm_request.contents,\n\u001b[32m    184\u001b[39m       config=llm_request.config,\n\u001b[32m    185\u001b[39m   )\n\u001b[32m    186\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    187\u001b[39m   logger.debug(_build_response_log(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/models.py:6778\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6776\u001b[39m response = types.GenerateContentResponse()\n\u001b[32m   6777\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6778\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   6779\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   6780\u001b[39m   )\n\u001b[32m   6781\u001b[39m   remaining_remote_calls_afc -= \u001b[32m1\u001b[39m\n\u001b[32m   6782\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m remaining_remote_calls_afc == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/models.py:5613\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5610\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   5611\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5613\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5614\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5615\u001b[39m )\n\u001b[32m   5617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5618\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5619\u001b[39m ):\n\u001b[32m   5620\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1365\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1354\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1355\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1356\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1359\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1360\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1361\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1362\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1363\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1366\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1367\u001b[39m   )\n\u001b[32m   1368\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1369\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1310\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1308\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1312\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1290\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1282\u001b[39m   \u001b[38;5;66;03m# aiohttp is not available. Fall back to httpx.\u001b[39;00m\n\u001b[32m   1283\u001b[39m   client_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_httpx_client.request(\n\u001b[32m   1284\u001b[39m       method=http_request.method,\n\u001b[32m   1285\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1288\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1289\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(client_response)\n\u001b[32m   1291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response.headers, [client_response.text])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI Engineering/.venv/lib/python3.13/site-packages/google/genai/errors.py:166\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2, model: gemini-2.5-pro\\nPlease retry in 32.726169318s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}, 'quotaValue': '2'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import traceback\n",
    "import contextlib\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Google ADK Imports\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.genai import types\n",
    "\n",
    "# =====================================================================\n",
    "# 1. SETUP & AUTH\n",
    "# =====================================================================\n",
    "\n",
    "load_dotenv()\n",
    "try:\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found.\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"âœ… Configuration Complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Auth Error: {e}\")\n",
    "\n",
    "# Retry config to handle transient API issues\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[400, 429, 500, 503, 504],\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# 2. PERSISTENT PYTHON KERNEL (LAYER 3)\n",
    "# =====================================================================\n",
    "\n",
    "class PersistentPythonSession:\n",
    "    \"\"\"\n",
    "    A persistent Python execution environment.\n",
    "\n",
    "    - Uses a shared namespace so variables (e.g., df) survive between calls.\n",
    "    - Captures stdout/stderr and returns it as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.namespace = {\n",
    "            \"pd\": pd,\n",
    "            \"__builtins__\": __builtins__,\n",
    "        }\n",
    "\n",
    "    def execute(self, script: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute arbitrary Python code in a persistent namespace and\n",
    "        capture stdout/stderr as a string.\n",
    "        \"\"\"\n",
    "        output_buffer = io.StringIO()\n",
    "        try:\n",
    "            with contextlib.redirect_stdout(output_buffer), contextlib.redirect_stderr(output_buffer):\n",
    "                exec(script, self.namespace, self.namespace)\n",
    "            result = output_buffer.getvalue()\n",
    "            if not result:\n",
    "                result = \"(Success. No output printed. Remember to print results!)\"\n",
    "            return result\n",
    "        except Exception:\n",
    "            return f\"Runtime Error: {traceback.format_exc()}\"\n",
    "\n",
    "\n",
    "# Initialize Global Session\n",
    "session = PersistentPythonSession()\n",
    "\n",
    "\n",
    "def run_python_kernel(script: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool used by the DataEngineer agent to execute Python code\n",
    "    inside the persistent session.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ§ª [ENGINEER -> KERNEL] Executing script:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(script)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    result = session.execute(script)\n",
    "\n",
    "    print(\"\\nðŸ“¤ [KERNEL OUTPUT]\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return result\n",
    "\n",
    "# =====================================================================\n",
    "# 3. DATA ENGINEER AGENT (LAYER 2)\n",
    "# =====================================================================\n",
    "\n",
    "ENGINEER_PROMPT = \"\"\"\n",
    "You are a Senior Python Data Engineer working in a persistent Python environment.\n",
    "\n",
    "CONTEXT:\n",
    "- You receive high-level analytical requests from a \"Lead Analyst\" manager agent.\n",
    "- The manager describes the datasets and data sources based on the user's request.\n",
    "- Datasets may be CSV files, tables, or other data sources. Do not assume any specific\n",
    "  filename or schema. Always rely on what the manager explicitly tells you.\n",
    "\n",
    "GOAL:\n",
    "- Translate the manager's requests into robust, efficient Pandas code and run it.\n",
    "\n",
    "RULES:\n",
    "\n",
    "1. Persistent State:\n",
    "   - The Python environment is stateful.\n",
    "   - If you create a DataFrame like `df` or `sales_df`, it will still exist later.\n",
    "   - Only load or create data structures when explicitly requested by the manager.\n",
    "   - Respect the names the manager gives you (e.g. \"load file X into df\").\n",
    "\n",
    "2. Tool Usage:\n",
    "   - To execute ANY Python code, ALWAYS use the `run_python_kernel` tool.\n",
    "   - Pass a complete, runnable Python script string.\n",
    "   - If the manager says \"assume the file is in the current folder\", use a relative path.\n",
    "\n",
    "3. Error Handling:\n",
    "   - If the kernel output starts with 'Runtime Error:', treat that as a failure.\n",
    "   - Think about what probably went wrong (e.g. wrong column name, wrong path, type issue).\n",
    "   - Propose a fix and call `run_python_kernel` again with corrected code.\n",
    "   - Explain in simple terms what changed and why.\n",
    "\n",
    "4. Output Formatting:\n",
    "   - Before executing code, briefly explain (1â€“3 sentences) what you will do,\n",
    "     referring to the dataset(s) and columns by the names given by the manager.\n",
    "   - In the code, use print() for:\n",
    "       - df.head()\n",
    "       - df.info() or df.dtypes\n",
    "       - groupby / aggregation results\n",
    "       - correlation matrices\n",
    "       - any key statistics or intermediate results\n",
    "   - After seeing the kernel output (conceptually), summarize the main findings\n",
    "     in clear natural language. You do NOT need to repeat every line of output,\n",
    "     just the important insights.\n",
    "\n",
    "5. Scope of Work:\n",
    "   - You are not responsible for high-level business hypotheses.\n",
    "   - Focus on:\n",
    "       - loading/merging datasets requested by the manager\n",
    "       - cleaning and transforming data\n",
    "       - grouping, aggregating, computing correlations\n",
    "       - running the specific checks/tests requested\n",
    "   - Always stay aligned with the manager's instructions and the user's described problem.\n",
    "\"\"\"\n",
    "\n",
    "engineer_agent = LlmAgent(\n",
    "    name=\"DataEngineer\",\n",
    "    model=Gemini(model=\"gemini-2.5-pro\", retry_options=retry_config),\n",
    "    instruction=ENGINEER_PROMPT,\n",
    "    tools=[run_python_kernel],\n",
    ")\n",
    "\n",
    "ENGINEER_APP_NAME = \"data_engineer_app\"\n",
    "ENGINEER_USER_ID = \"internal_user\"\n",
    "ENGINEER_SESSION_ID = \"internal_engineer_session\"\n",
    "\n",
    "# Runner for the Engineer (stateful)\n",
    "engineer_runner = InMemoryRunner(agent=engineer_agent, app_name=ENGINEER_APP_NAME)\n",
    "\n",
    "# =====================================================================\n",
    "# 4. BRIDGE TOOL: MANAGER â†’ ENGINEER\n",
    "# =====================================================================\n",
    "\n",
    "async def ask_data_engineer(request: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool that the LeadAnalyst uses to send natural-language instructions\n",
    "    to the DataEngineer agent.\n",
    "\n",
    "    Internally:\n",
    "    - Ensures a persistent session for the DataEngineer.\n",
    "    - Streams all Engineer events (text + tool calls).\n",
    "    - Aggregates textual responses into a single string.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“¢ [MANAGER -> ENGINEER]: {request}\")\n",
    "\n",
    "    try:\n",
    "        # Ensure the Engineer session exists (idempotent)\n",
    "        try:\n",
    "            await engineer_runner.session_service.create_session(\n",
    "                app_name=ENGINEER_APP_NAME,\n",
    "                user_id=ENGINEER_USER_ID,\n",
    "                session_id=ENGINEER_SESSION_ID,\n",
    "            )\n",
    "            print(f\"ðŸ§µ [ENGINEER SESSION] Created/using session '{ENGINEER_SESSION_ID}'.\")\n",
    "        except Exception as e:\n",
    "            # If it already exists, that's fine\n",
    "            print(f\"â„¹ï¸ [ENGINEER SESSION] Using existing session '{ENGINEER_SESSION_ID}': {e}\")\n",
    "\n",
    "        user_msg = types.UserContent(parts=[types.Part(text=request)])\n",
    "\n",
    "        full_response_text: list[str] = []\n",
    "\n",
    "        # Stream of events coming from the Engineer\n",
    "        async for event in engineer_runner.run_async(\n",
    "            user_id=ENGINEER_USER_ID,\n",
    "            session_id=ENGINEER_SESSION_ID,\n",
    "            new_message=user_msg,\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                role = getattr(event.content, \"role\", \"model\")\n",
    "                print(f\"\\nðŸ¤– [ENGINEER EVENT] role={role}\")\n",
    "\n",
    "                for part in event.content.parts:\n",
    "                    # Text from Engineer\n",
    "                    if getattr(part, \"text\", None):\n",
    "                        print(\"   ðŸ—£ï¸ ENGINEER TEXT:\")\n",
    "                        print(\"   \" + part.text.replace(\"\\n\", \"\\n   \"))\n",
    "                        full_response_text.append(part.text)\n",
    "\n",
    "                    # Tool calls (e.g. run_python_kernel)\n",
    "                    if getattr(part, \"function_call\", None):\n",
    "                        fc = part.function_call\n",
    "                        print(\"   ðŸ› ï¸ ENGINEER TOOL CALL:\")\n",
    "                        print(f\"      name: {fc.name}\")\n",
    "                        print(f\"      args: {fc.args}\")\n",
    "\n",
    "        output_text = \"\".join(full_response_text).strip()\n",
    "\n",
    "        if not output_text:\n",
    "            output_text = \"(Task completed by Engineer. Check logs above for kernel output and messages.)\"\n",
    "\n",
    "        print(f\"\\nðŸ“‰ [ENGINEER -> MANAGER]: Final aggregated response delivered.\")\n",
    "        return output_text\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Data Engineer System Error: {str(e)}\"\n",
    "        print(f\"âŒ [ENGINEER ERROR]: {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "# =====================================================================\n",
    "# 5. LEAD ANALYST AGENT (LAYER 1)\n",
    "# =====================================================================\n",
    "\n",
    "MANAGER_PROMPT = \"\"\"\n",
    "You are the Lead Data Analyst. You manage a specialized \"Data Engineer\" who writes and executes code for you.\n",
    "You do not write code yourself; you think strategically and scientifically.\n",
    "\n",
    "CONTEXT:\n",
    "- The human user will describe:\n",
    "    - One or more datasets (e.g. CSV files, tables, views)\n",
    "    - The business question or analytical goal\n",
    "- You must always ground your reasoning in the datasets and goals described\n",
    "  in the USER'S QUERY, not in any fixed example dataset.\n",
    "- You have a tool `ask_data_engineer(request=\"...\")` that can translate your analytical\n",
    "  requests into actual code and run it on the data.\n",
    "\n",
    "GENERAL WORKFLOW (ADAPTED TO ANY DATASET):\n",
    "\n",
    "PHASE 1 â€“ EXPLORATION\n",
    "- From the USER'S QUERY, identify:\n",
    "  - Which dataset(s) should be loaded (filenames, tables, etc.).\n",
    "  - The likely target metrics and key dimensions.\n",
    "- Use ask_data_engineer(request=\"...\") to:\n",
    "  - Load the dataset(s) the user mentioned into appropriately named DataFrames (e.g. df, df_sales).\n",
    "  - Show a small sample (head), the schema (dtypes/info), and basic descriptive stats.\n",
    "- From the Engineer's summary, clarify:\n",
    "  - The main time dimension(s) (e.g. date, day, month), if any.\n",
    "  - The main outcome metrics (e.g., revenue, conversions, TTI, error rate, etc.).\n",
    "  - Any important categorical segments (e.g., country, device, channel, segment, endpoint).\n",
    "\n",
    "PHASE 2 â€“ HYPOTHESIS FORMULATION\n",
    "- Based on the exploration and the userâ€™s goal, define exactly 3 hypotheses.\n",
    "- Use the following format:\n",
    "  - H1: [short hypothesis statement about a potential driver or relationship]\n",
    "  - H2: ...\n",
    "  - H3: ...\n",
    "- Each hypothesis should explain a potential DRIVER of the patterns in the dataset(s)\n",
    "  the user cares about (e.g. segments, time effects, correlations between metrics).\n",
    "\n",
    "PHASE 3 â€“ TESTING\n",
    "- For each hypothesis (H1, H2, H3):\n",
    "  - Use ask_data_engineer(request=\"...\") to request specific computations.\n",
    "  - Examples of useful operations (adapt to the actual data and goal):\n",
    "      - groupby on segments (e.g., endpoint, region, device, channel)\n",
    "      - correlation between metrics (e.g. traffic vs. errors, TTI vs. conversion)\n",
    "      - time-based analyses (trends, before/after periods, weekday vs weekend, etc.)\n",
    "  - Ask the Engineer to produce compact tables and relevant statistics, not huge dumps.\n",
    "- After each Engineer response:\n",
    "  - Interpret the evidence.\n",
    "  - Decide whether each hypothesis is:\n",
    "      - Supported\n",
    "      - Not supported\n",
    "      - Inconclusive\n",
    "  - Briefly justify your decision, referencing the Engineer's results.\n",
    "\n",
    "PHASE 4 â€“ SYNTHESIS & REPORT\n",
    "- Summarize in a short analytical report:\n",
    "  - The key drivers or relationships you discovered in the dataset(s) the user described.\n",
    "  - Which hypotheses were accepted, rejected, or remained inconclusive.\n",
    "  - Any surprising or non-obvious insights that emerged.\n",
    "- Use clear headings and concise, business-oriented language.\n",
    "\n",
    "TOOL USAGE:\n",
    "- Treat ask_data_engineer(request=\"...\") as your interface to the underlying Python environment.\n",
    "- Do NOT write code yourself; always express what you need in natural language.\n",
    "- Keep your requests specific and grounded in the columns, metrics, and datasets\n",
    "  mentioned by the user.\n",
    "\n",
    "REQUIREMENT:\n",
    "At the very end of your response, always include a section:\n",
    "\n",
    "### ðŸ”­ Future Exploration\n",
    "\n",
    "In this section, list 3â€“5 concrete next questions or analyses that could be run\n",
    "in future iterations, tailored to the user's data and goal\n",
    "(e.g., \"Test seasonality by month\", \"Compare pre- and post-release performance\",\n",
    "      \"Model uplift after a campaign\", \"Drill into a specific endpoint or segment\").\n",
    "\"\"\"\n",
    "\n",
    "lead_analyst = LlmAgent(\n",
    "    name=\"LeadAnalyst\",\n",
    "    model=Gemini(model=\"gemini-2.5-pro\", retry_options=retry_config),\n",
    "    instruction=MANAGER_PROMPT,\n",
    "    tools=[ask_data_engineer],\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# 6. EXECUTION\n",
    "# =====================================================================\n",
    "\n",
    "# ðŸ‘‰ EXAMPLE user query.\n",
    "# You can change this to any other dataset/problem;\n",
    "# the prompts are now fully generic.\n",
    "user_query = \"\"\"\n",
    "I have a CSV file named 'Euro_Daily_Trends.csv' in the current folder.\n",
    "It contains daily metrics for different European entities.\n",
    "\n",
    "I want to understand the drivers behind the main trends in this dataset.\n",
    "Please follow your exploration â†’ hypotheses â†’ testing â†’ synthesis workflow,\n",
    "and focus on finding non-obvious relationships rather than just describing the data.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- ðŸ§  Lead Analyst Team Started ---\")\n",
    "runner = InMemoryRunner(agent=lead_analyst, app_name=\"lead_analyst_app\")\n",
    "\n",
    "\n",
    "\n",
    "await runner.run_debug(user_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
