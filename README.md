# AI-Agents-Intensive-Course-with-Google---Capstone-Project

# Multi-Agent Data Analysis Framework (Google ADK + Gemini)

A small but powerful example of **agentic analytics** using:

- **LeadAnalyst** â€“ a strategic data analyst agent  
- **DataEngineer** â€“ a Python / Pandas engineer agent  
- **Persistent Python kernel** â€“ shared state across all tool calls  
- **Google ADK + Gemini 2.5 Pro** â€“ reasoning + tool orchestration

The system takes a **natural language request** from the user, explores the dataset, formulates hypotheses, tests them via code, and returns a structured analytical report.  
It is **generic**: it works with any tabular dataset you describe in your prompt (not hard-coded to a specific CSV).

---

## âœ¨ Core Idea

Instead of a single LLM â€œdoing everythingâ€, we split roles:

- The **LeadAnalyst**:
  - Understands the userâ€™s business question
  - Designs an analytical plan
  - Delegates technical work to the DataEngineer
  - Synthesizes results and writes the final report (with a â€œFuture Explorationâ€ section)

- The **DataEngineer**:
  - Receives natural language instructions from LeadAnalyst
  - Writes and executes **Pandas code** via a tool (`run_python_kernel`)
  - Works in a **persistent Python session** (variables like `df` live across calls)
  - Summarizes code results in natural language

This pattern is reusable for many problems: performance analytics, business KPIs, experimentation, diagnostics, etc.

---

## ğŸ§± Architecture

High-level components:

1. **PersistentPythonSession**
   - Holds a shared `namespace` (like a notebook kernel).
   - Executes arbitrary Python code with `exec()` and returns stdout/stderr as a string.
   - Exposes `pd` (Pandas) and builtins by default.

2. **Tool: `run_python_kernel(script: str) -> str`**
   - Simple wrapper around the persistent session.
   - Logs:
     - The Python script generated by the agent
     - The execution output (prints, errors, etc.)

3. **DataEngineer Agent (`LlmAgent`)**
   - Instruction: â€œYou are a Senior Python Data Engineerâ€¦â€
   - Responsibilities:
     - Load / transform / aggregate / join data as requested.
     - Use **only** the `run_python_kernel` tool to execute code.
     - Handle errors (detect â€œRuntime Errorâ€ in output, fix code, retry).
     - Summarize key findings instead of dumping raw logs.

4. **Bridge Tool: `ask_data_engineer(request: str) -> str`**
   - Exposed to the LeadAnalyst as a tool.
   - Internally runs the DataEngineer via `engineer_runner.run_async(...)`.
   - Logs:
     - Manager â†’ Engineer requests
     - Engineer events (text + tool calls)
     - Final Engineer response

5. **LeadAnalyst Agent (`LlmAgent`)**
   - Instruction: â€œYou are the Lead Data Analystâ€¦â€
   - Generic workflow (works for any dataset described by the user):
     - Phase 1 â€“ Exploration  
     - Phase 2 â€“ Hypothesis Formulation  
     - Phase 3 â€“ Testing  
     - Phase 4 â€“ Synthesis & Report  
   - Uses `ask_data_engineer` to request code-level work.
   - Always ends with a `### ğŸ”­ Future Exploration` section.

6. **Runner**
   - `InMemoryRunner` for each agent.
   - `run_debug` is used to show streaming events and make debugging easier.

---
